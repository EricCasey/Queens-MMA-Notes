# Course: MMA 863 - MMA Math & Stats Preview
#### Instructor: Keith Rogers
#### Email: 
#### Website: 

"It's when you lose track of your assumptions that you find yourself in trouble."

<!-- ![alt text](/img/nrmlcurve.png "Normal Curve") -->

--------------------- 
## Part 1: The Basics
---------------------
### Types & Representation of Data


### Populations & Samples
* Population: All relevant items of interest
* Sample: A random sub-section of the population

DGP - Data Generating Process
    * 

### Descriptive Stats
Descriptive Stats:
> The presentation of information or conclusions based on either a sample or a population. For example, to present the daily production volume over the past year for a sample of employees

Inferential Stats: 
> The use of sample data to reach a conclusion about a population. For example, to determine if production levels are increasing over time, or if they fall by more than 10% after a long weekend

### Types of Data [basic-->neat]

#### Data-type Hierarchy
* Nominal [Male/Female]
    * True/False, in-category or out
    * Numeric values have no meaning
* Ordinal [Low/Medium/High]
    * Rank is meaningful
    * Range between
    * Levels of satisfaction
* Interval [Temperature]
    * Distance between values have meaning
    * No absolute 0
    * Percentages don't make sense
* Ration [starting salary]
    * Distance between has value
    * There IS an abslute 0
    * Percentage makes sense

#### Time-Related Data
* Cross-Sectional
    * No time dimension
* Time-Series Data
    * Where time matters
* Panel Data
    * Blending of Time-Series & Cross Sectional

### Story Telling
* Summary Stats
    * Mean, Median, Mode
    * Q1, Q3, IQR (Interquartile Range)
    * P-value
    * Variance (&sigma;<sup>2</sup>)
    * Stan Dev (&sigma;)
* Tables
* Graphs/Charts
    * Shapes of Histograms
        * Bell Shaped 
            * denotes central limit theorum
            * Empirical rule
                * If a distribution is bell-shapes, 68% are within 1 &sigma;
            * Chebyshev's Theorum
                * _something else_
        * Skew (pos/neg)
            * "Ski you to the left?"
            * "Ski you to the rignt?"
        * Bi-Modal
            * Two Humps

<p align="center">
  <img src="https://psychologywithmisssmith.files.wordpress.com/2017/01/img_3741.png"/>
</p>

* Models


---------------------
## Part 2: Probability
---------------------

#### Gambler's Fallacy
> The belief that 'runs' occur to statistically independent phenomena such as roulette wheel spins.

#### Hot Head Fallacy
> I just won solo fortnite with no kills
> So I must be good

#### Available Heuristic
> tendency to overestimate the likelihood of events with greater availability in memory.

#### Base Rate Fallacy / Base Rate Neglect
> Tendencies to ingnore base rate information and focus on specific information

#### Conjunction Fallacy
> Tendency to assume tha tdpecific conditionare are more probably than others

#### Experimenter's Bias 
> tendency for experimenter to belive data that agrees with their expectations

#### Neglect of Probability
> Tendency to disregard probability when making a decision under uncertainlty

#### Overconfidence effect
> Excessive confidence in one's own answers to questions (I'm 99% sure, but only 40% get it correct)


### Foundations

_What is probability?_
* Classical
    * 
* Relative Requency
    * The rate at which something happens in the data
* Subjective
    * 

### Rules

#### Rules of Probability
> Probabilities apply to events (i.e. one outcum of an experiment) within a sample space. An elementary event is an event that cannot be decomposed into other events. A sample space is the collection of all possible elemnentary events associated with an outcome.

#### Events
* Mutually exclusive events
    * Not independent events, like heads and tails, can't happen at the same time.
* Independaent events
    * Where the event has nothing to do with the probability of the other events.
* Complement of an event
    * Is the event that makes up the rest of the sample space.
    * _"The complementary rule of haircuts"_ - Keith Rodgers
        * Ask them if they've recently had a haircut, the answer is always "it looks nice".
* Collectively exhaustive events
    * The full list of all events.
* Union 
    * { 1, 2 } â‹ƒ { 2, 3 } = { 1, 2, 3 }
    * The union of two events is the collection of elemnets that exist in either of them. 

<p align="center">
  <img src="/img/probtypes.png"/>
</p>

### Bayes Theorum
    * 

### Visual Ways To Solve Problems
* Trees
    * Hierarchical tree thigns to plot out numbers
* Tables
    * A Matrix
 * Formulae
    * Just writing it all out.

0.5

---------------------
## Part 3: Probability Distributions
---------------------

### Random Variables
_... is a rule or function that assigns a numericcalue to the outcomes of a random experiement_

#### Discrete Distributions [COUNTABLE]
> Probability Mass Functions
> "How Many Dollars Do You Have?"
_countable, even if there are infinite possiblities. But no in-between numbers or decimals_

##### Binomial
>"Maximum Upper Limit"

`=BINOM.DIST(num,trials,prob,bool)`

- Fixed number of independent trials.
- Success of Failure only.
- RV is the number of successes.
- We have an experiment involving n identical trials.
- There are only possible outcome: success or a fail

##### Poisson
>"Can always imagine more"

`=POISSON.DIST(num,trials,prob,bool)`

- Things happen randomlt at a fixed rate.
- RV is the # of occurrences.
- The number of events that occur in any interval is independent of the number of events that occur in any other interval.
- The probability of an event in an interal is the same for all equal sized intervals.



#### Continuous Distributions [UNCOUNTABLE]
> Probability Density Functions
> "How Much Money Do You Have"
_non-countable, more measurable. Like distance being 0.0001 cm or time being 0.00001 min_

##### Zeno's Paradox
> Technically this arrow is constantly approaching the halfway point between archer and target.
<p align="center">
  <img src="https://i1.wp.com/www.naturphilosophie.co.uk/wp-content/uploads/2015/05/Zeno_Paradox_Never_Reaching_Arrow.jpg"/>
</p>

##### Uniform
> a Uniformly distributed random variable is one wher all equally sized interval within the variable range have equal probability of occuring. Like a clock, infinite possible positions, but standard scale.

##### Normal
> &sigma; = Standard Deviation
> &sigma;<sup>2</sup> = Variance
> &mu; = Mean
> Z = z-score = (x - &mu;) / &sigma;
> 

* Normal Distribution
`=NORM.DIST(x,mean,standev,bool)`
* Normal Standard Distribution
Z-Score to Probability: `=NORM.S.DIST(z,bool)`
Probability to Z-Score`=NORM.S.INV(probability)`

<p align="center">
  <img src="/img/nrmlcurve.png"/>
</p>


---------------------
## Part 4: Sampling Distributions
---------------------

Central Limits Theorum
* 
### Sampling Distribution

### Interval Estimation

### Sample Size Determination
